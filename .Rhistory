train_df.head()
train_df = pd.read_csv(dataset_path/'train.csv', sep='\t')
train_df.head()
train_df['path'] = train_df['image_name'].map(lambda x:dataset_path/'train'/x)
train_df = train_df.drop(columns=['image_name'])
train_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe
train_df.head(10)
len_df = len(train_df)
print(f"There are {len_df} images")
train_df['label'].hist(figsize = (10, 5))
train_df['label_id'].hist(figsize = (10, 5))
matplotlib.use('Agg')
plt.use('Agg')
import matplotlib as plt
plt.pyplot.style.use("ggplot")
plt.use('Agg')
train_df['label_id'].hist(figsize = (10, 5))
plt.show()
plt.pyplot.show()
class ArtDataset(Dataset):
def __init__(self, root_dir, csv_path=None, transform=None):
self.transform = transform
self.files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
self.targets = None
if csv_path:
df = pd.read_csv(csv_path, sep="\t")
self.targets = df["label_id"].tolist()
self.files = [os.path.join(root_dir, fname) for fname in df["image_name"].tolist()]
def __len__(self):
return len(self.files)
def __getitem__(self, idx):
image = Image.open(self.files[idx]).convert('RGB')
target = self.targets[idx] if self.targets else -1
if self.transform:
image = self.transform(image)
return image, target
MODEL_WEIGHTS = "./baseline.pt"
TRAIN_DATASET = "../train/"
TRAIN_CSV = "train.csv"
MODEL_WEIGHTS = "baseline.pt"
TRAIN_DATASET = "/train/"
def get_image_metadata(file_path):
with Image.open(file_path) as img:
metadata = img._getexif()
return metadata
root_dir = '/train/'
files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
root_dir = '../train/'
files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
root_dir = 'C:/Users/user/OneDrive/Документы/GitHub/baseline-master/train/'
files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
metadata_list = []
for file_path in files:
metadata = get_image_metadata(file_path)
metadata_list.append(metadata)
for file_path in files:
metadata = get_image_metadata(file_path)
metadata_list.append(metadata)
import pyexiv2
!pip install pyexiv2
import pyexiv2
def get_image_metadata(file_path):
metadata = pyexiv2.ImageMetadata(file_path)
metadata.read()
return metadata.__dict__
metadata_list = []
for file_path in files:
metadata = get_image_metadata(file_path)
metadata_list.append(metadata)
def get_image_metadata(file_path):
metadata = pyexiv2.Image(file_path)
metadata.readMetadata()
return metadata.exifKeys
metadata_list = []
metadata_list = []
for file_path in files:
metadata = get_image_metadata(file_path)
metadata_list.append(metadata)
def get_image_metadata(file_path):
with open(file_path, 'rb') as f:
tags = exifread.process_file(f)
return tags
import exifread
!pip install exifread
import exifread
for file_path in files:
metadata = get_image_metadata(file_path)
metadata_list.append({'Filename': file_path, 'Metadata': metadata})
df = pd.DataFrame(metadata_list, columns=['Filename', 'Metadata'])
df.head()
metadata_list = []
for file_path in files:
mod_time = os.path.getmtime(file_path)
metadata_list.append({'Filename': file_path, 'Modification Time': mod_time})
df = pd.DataFrame(metadata_list)
df.head()
for file_path in files:
mod_time = os.path.getmtime(file_path)
date = datetime.datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d')
metadata_list.append({'Filename': file_path, 'Modification Date': date})
import datetime
metadata_list = []
for file_path in files:
mod_time = os.path.getmtime(file_path)
date = datetime.datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d')
metadata_list.append({'Filename': file_path, 'Modification Date': date})
df = pd.DataFrame(metadata_list)
df.head()
for file_path in files:
mod_time = os.path.getmtime(file_path)
time = datetime.datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M:%S')
metadata_list.append({'Filename': file_path, 'Modification Time': time})
df = pd.DataFrame(metadata_list)
metadata_list = []
for file_path in files:
mod_time = os.path.getmtime(file_path)
time = datetime.datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M:%S')
metadata_list.append({'Filename': file_path, 'Modification Time': time})
df = pd.DataFrame(metadata_list)
df.head()
df['Modification Time'].hist(figsize = (10, 5))
plt.pyplot.show()
df.head(20)
metadata_list = []
for file_path in files:
mod_time = os.path.getmtime(file_path)
time = datetime.datetime.fromtimestamp(mod_time).strftime('%H:%M')
metadata_list.append({'Filename': file_path, 'Modification Time': time})
df = pd.DataFrame(metadata_list)
df.head(20)
train_metadata = pd.DataFrame(metadata_list)
len(df)
print(f"There are {len_df} images")
train_df.head(10)
os.listdir(dataset_path)
train_df = pd.read_csv(dataset_path/'train.csv', sep='\t')
train_df.head()
df.head()
root_dir = "/train/"
files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
root_dir = "/train"
files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
root_dir = "train"
files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
root_dir = "train\\"
files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
root_dir = "train//"
files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
root_dir = "train/"
files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
metadata_list = []
for file_path in files:
mod_time = os.path.getmtime(file_path)
time = datetime.datetime.fromtimestamp(mod_time).strftime('%H:%M')
metadata_list.append({'Filename': file_path, 'Modification Time': time})
df.head()
train_metadata = pd.DataFrame(metadata_list)
train_metadata.head()
train_df.head()
train_metadata['Filename'] = train_metadata['Filename'].str.replace("train/", "")
train_metadata.head()
result_df = train_df.merge(train_metadata, left_on='image_name', right_on='Filename', how='left')
result_df.head()
result_df
View(result_df)
result_df = result_df.drop(columns = ['Filename'])
result_df
root_dir = "test/"
files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
metadata_list = []
for file_path in files:
mod_time = os.path.getmtime(file_path)
time = datetime.datetime.fromtimestamp(mod_time).strftime('%H:%M')
metadata_list.append({'Filename': file_path, 'Modification Time': time})
test_metadata = pd.DataFrame(metadata_list)
test_metadata.head()
test_metadata['Filename'] = train_metadata['Filename'].str.replace("train/", "")
test_metadata.head()
time_label_map = {}
for index, row in result_df.iterrows():
time = row['Modification Time']
label = row['label_id']
time_label_map[time] = label
for i, row in result_df.iterrows():
time_label_map[row['Modification Time']] = row['label_id']
time_label_map
test_df = test_metadata.copy()
test_df['label_id'] = test_df['Modification Time'].map(time_label_map)
test_df.head()
result_df['Modification time'].hist(figsize = (10, 5))
result_df['Modification Time'].hist(figsize = (10, 5))
plt.pyplot.show()
pd.Categorical(result_df['Modification Time']).hist(figsize = (10, 5))
res_df = result_df
res_df['Modification Time'] = pd.Categorical(res_df['Modification Time'])
res_df['Modification Time'].hist(figsize = (10, 5))
plt.pyplot.show()
train_df.head(10)
test_df.head()
train_df = pd.read_csv(dataset_path/'train.csv', sep='\t')
train_df.head()
int main(void)
{
int wordsCount = 0;
char wordsArray[100];
fgets(wordsArray, sizeof(wordsArray), stdin);
int len = strlen(wordsArray);
int i;
int prevSpace = 1;
for (i = 0; i < len; i++)
{
if (wordsArray[i] != ' ')
{
if (prevSpace)
{
wordsCount++;
prevSpace = 0;
}
}
else
{
prevSpace = 1;
}
}
printf("%d\n", wordsCount);
return 0;
}
class ArtDataset(Dataset):
def __init__(self, root_dir, csv_path=None, transform=None):
self.transform = transform
self.files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
self.targets = None
if csv_path:
df = pd.read_csv(csv_path, sep="\t")
self.targets = df["label_id"].tolist()
self.files = [os.path.join(root_dir, fname) for fname in df["image_name"].tolist()]
def __len__(self):
return len(self.files)
def __getitem__(self, idx):
image = Image.open(self.files[idx]).convert('RGB')
target = self.targets[idx] if self.targets else -1
if self.transform:
image = self.transform(image)
return image, target
def set_requires_grad(model, value=False):
for param in model.parameters():
param.requires_grad = value
def train_model(model, dataloaders, criterion, optimizer, phases, num_epochs=3):
start_time = time.time()
acc_history = {k: list() for k in phases}
loss_history = {k: list() for k in phases}
for epoch in range(num_epochs):
print('Epoch {}/{}'.format(epoch, num_epochs - 1))
print('-' * 10)
# Each epoch has a training and validation phase
for phase in phases:
if phase == 'train':
model.train()  # Set model to training mode
else:
model.eval()  # Set model to evaluate mode
running_loss = 0.0
running_corrects = 0
# Iterate over data.
n_batches = len(dataloaders[phase])
for inputs, labels in tqdm(dataloaders[phase], total=n_batches):
inputs = inputs.to(device)
labels = labels.to(device)
# zero the parameter gradients
optimizer.zero_grad()
# forward
# track history if only in train
with torch.set_grad_enabled(phase == 'train'):
outputs = model(inputs)
loss = criterion(outputs, labels)
_, preds = torch.max(outputs, 1)
# backward + optimize only if in training phase
if phase == 'train':
loss.backward()
optimizer.step()
# statistics
running_loss += loss.item() * inputs.size(0)
running_corrects += torch.sum(preds == labels.data)
epoch_loss = running_loss / len(dataloaders[phase].dataset)
epoch_acc = running_corrects.double()
epoch_acc /= len(dataloaders[phase].dataset)
print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss,
epoch_acc))
loss_history[phase].append(epoch_loss)
acc_history[phase].append(epoch_acc)
print()
time_elapsed = time.time() - start_time
print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60,
time_elapsed % 60))
return model, acc_history
def init_model(device, num_classes):
model = torchvision.models.mobilenet_v3_small(pretrained=True)
set_requires_grad(model, False)
model.classifier[3] = torch.nn.Linear(model.classifier[0].out_features, num_classes)
model = model.to(device)
return model
def init_model(device, num_classes):
model = timm.create_model("MaxViT-xl-tf-512", pretrained=True, in_chans=3, num_classes=num_classes)
model = model.to(device)
return model
def init_model(device, num_classes):
model = timm.create_model("MaxViT-xl-tf-512", pretrained=True, in_chans=3, num_classes=num_classes)
model = model.to(device)
return model
class ArtDataset(Dataset):
def __init__(self, root_dir, csv_path=None, transform=None):
self.transform = transform
self.files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
self.targets = None
if csv_path:
df = pd.read_csv(csv_path, sep="\t")
self.targets = df["label_id"].tolist()
self.files = [os.path.join(root_dir, fname) for fname in df["image_name"].tolist()]
def __len__(self):
return len(self.files)
def __getitem__(self, idx):
image = Image.open(self.files[idx]).convert('RGB')
target = self.targets[idx] if self.targets else -1
if self.transform:
image = self.transform(image)
return image, target
MODEL_WEIGHTS = "baseline.pt"
TRAIN_DATASET = "train/"
TRAIN_CSV = "train.csv"
from fastai.vision import *
!pip install fastai
from fastai.vision import *
def get_transforms(img_size):
return transforms.Compose([
transforms.Resize((img_size, img_size)),
transforms.ToTensor(),
transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
data = ImageDataBunch.from_csv(TRAIN_DATASET, csv_labels=TRAIN_CSV,
ds_tfms=get_transforms(), size=224, bs=32)
from fastai.vision import *
data = ImageDataBunch.from_csv(TRAIN_DATASET, csv_labels=TRAIN_CSV,
ds_tfms=get_transforms(), size=224, bs=32)
from fastai.data.transforms import get_transforms
from fastai.vision.data import ImageDataLoaders
def get_transforms(img_size):
return get_transforms(do_flip=False, flip_vert=False, max_rotate=0.0,
max_zoom=1.0, max_lighting=0.0, max_warp=0.0,
p_affine=0.75, p_lighting=0.75,
xtra_tfms=[])
data = ImageDataLoaders.from_csv(TRAIN_DATASET, csv_labels=TRAIN_CSV,
item_tfms=get_transforms(img_size=224),
batch_size=32)
from fastai.data.block import DataBlock, CategoryBlock
from fastai.tabular.all import TabularDataLoaders
transforms = [    Resize(img_size, img_size),    ToTensor(),    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
]
from fastai.vision.data import ResizeMethod
import fastai
transforms = [ Resize(img_size, img_size),
ToTensor(), Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
]
fastai.__version__
from PIL import Image
transforms = [ Resize(img_size, img_size),
ToTensor(), Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
]
reticulate::repl_python()
import fastai
from PIL import Image
transforms = [ Resize(img_size, img_size),ToTensor(), Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]
transforms = [Resize(img_size, img_size),ToTensor(), Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]
transforms = [Image.Resize(img_size, img_size),ToTensor(), Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]
transforms = transforms.Compose([
transforms.Resize((img_size, img_size)),
transforms.ToTensor(),
# transforms.Lambda(lambda x: x.repeat(3, 1, 1) if len(x.shape) == 2 or x.shape[-1] == 1 else x), # if Gray => make 3 channels
# transforms.Lambda(lambda x: x[:4, :, :]), # if 4 channels => make 3
transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
import torch
from torch import nn
import torchvision
from torchvision import transforms
from torch.utils.data import Dataset
from PIL import Image
import os
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import time
from tqdm import tqdm
import matplotlib as plt
plt.pyplot.style.use("ggplot")
plt.use('Agg')
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import timm
import gc
import random
from datetime import datetime
from pathlib import Path
def set_requires_grad(model, value=False):
for param in model.parameters():
param.requires_grad = value
def train_model(model, dataloaders, criterion, optimizer, phases, num_epochs=3):
start_time = time.time()
acc_history = {k: list() for k in phases}
loss_history = {k: list() for k in phases}
for epoch in range(num_epochs):
print('Epoch {}/{}'.format(epoch, num_epochs - 1))
print('-' * 10)
# Each epoch has a training and validation phase
for phase in phases:
if phase == 'train':
model.train()  # Set model to training mode
else:
model.eval()  # Set model to evaluate mode
running_loss = 0.0
running_corrects = 0
# Iterate over data.
n_batches = len(dataloaders[phase])
for inputs, labels in tqdm(dataloaders[phase], total=n_batches):
inputs = inputs.to(device)
labels = labels.to(device)
# zero the parameter gradients
optimizer.zero_grad()
# forward
# track history if only in train
with torch.set_grad_enabled(phase == 'train'):
outputs = model(inputs)
loss = criterion(outputs, labels)
_, preds = torch.max(outputs, 1)
# backward + optimize only if in training phase
if phase == 'train':
loss.backward()
optimizer.step()
# statistics
running_loss += loss.item() * inputs.size(0)
running_corrects += torch.sum(preds == labels.data)
epoch_loss = running_loss / len(dataloaders[phase].dataset)
epoch_acc = running_corrects.double()
epoch_acc /= len(dataloaders[phase].dataset)
print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss,
epoch_acc))
loss_history[phase].append(epoch_loss)
acc_history[phase].append(epoch_acc)
print()
time_elapsed = time.time() - start_time
print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60,
time_elapsed % 60))
return model, acc_history
def init_model(device, num_classes):
model = timm.create_model("MaxViT-xl-tf-512", pretrained=True, in_chans=3, num_classes=num_classes)
model = model.to(device)
return model
class ArtDataset(Dataset):
def __init__(self, root_dir, csv_path=None, transform=None):
self.transform = transform
self.files = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)]
self.targets = None
if csv_path:
df = pd.read_csv(csv_path, sep="\t")
self.targets = df["label_id"].tolist()
self.files = [os.path.join(root_dir, fname) for fname in df["image_name"].tolist()]
def __len__(self):
return len(self.files)
def __getitem__(self, idx):
image = Image.open(self.files[idx]).convert('RGB')
target = self.targets[idx] if self.targets else -1
if self.transform:
image = self.transform(image)
return image, target
img_dir = 'train/'
# hardcode
MODEL_WEIGHTS = "baseline.pt"
TRAIN_DATASET = "train/"
TRAIN_CSV = "train.csv"
transforms = transforms.Compose([
transforms.Resize((img_size, img_size)),
transforms.ToTensor(),
# transforms.Lambda(lambda x: x.repeat(3, 1, 1) if len(x.shape) == 2 or x.shape[-1] == 1 else x), # if Gray => make 3 channels
# transforms.Lambda(lambda x: x[:4, :, :]), # if 4 channels => make 3
transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
img_size = 245
transforms = transforms.Compose([
transforms.Resize((img_size, img_size)),
transforms.ToTensor(),
# transforms.Lambda(lambda x: x.repeat(3, 1, 1) if len(x.shape) == 2 or x.shape[-1] == 1 else x), # if Gray => make 3 channels
# transforms.Lambda(lambda x: x[:4, :, :]), # if 4 channels => make 3
transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
data = DataBlock(
blocks=(ImageBlock, CategoryBlock),
get_items=get_image_files,
get_y=parent_label,
item_tfms=transforms,
batch_tfms=[*aug_transforms, *transforms],
splitter=FuncSplitter(lambda o: random.random() < 0.2)
)
from fastai.data.block import DataBlock, CategoryBlock
from fastai.tabular.all import TabularDataLoaders
from fastai.vision.data import ResizeMethod
data = DataBlock(
blocks=(ImageBlock, CategoryBlock),
get_items=get_image_files,
get_y=parent_label,
item_tfms=transforms,
batch_tfms=[*aug_transforms, *transforms],
splitter=FuncSplitter(lambda o: random.random() < 0.2)
)
from fastai.data.block import FloatListBlock, CategoryBlock
from fastai.vision.all import *
data = ImageDataLoaders.from_csv(TRAIN_DATASET, csv_labels=TRAIN_CSV, item_tfms=Resize(img_size), batch_tfms=aug_transforms(), size=224, bs=32)
